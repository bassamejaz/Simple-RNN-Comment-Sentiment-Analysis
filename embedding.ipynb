{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sentences=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 10000\n",
    "one_hot_repr = [one_hot(sentence,voc_size) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3596, 5823, 1095, 5957],\n",
       " [3596, 5823, 1095, 9597],\n",
       " [3596, 2692, 1095, 8483],\n",
       " [8473, 3601, 7319, 6783, 8322],\n",
       " [8473, 3601, 7319, 6783, 7921],\n",
       " [6584, 3596, 9421, 1095, 3357],\n",
       " [6814, 1296, 7995, 6783]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one_hot() function from tensorflow.keras.preprocessing.text generates a unique integer representation for each word in the sentence.\n",
    "\n",
    "It does not perform traditional one-hot encoding (where each word is represented as a sparse vector of size equal to vocabulary size). Instead, it assigns a random but deterministic integer (between 1 and voc_size) to each word.\n",
    "\n",
    "The output will be a list of lists where each inner list contains integer values representing words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "max_sentence_length = 8\n",
    "embedded_doc = pad_sequences(one_hot_repr,padding=\"pre\",maxlen=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ANNProject/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dim = 10\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=max_sentence_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04967687,  0.02662567,  0.01981434, -0.01477013,\n",
       "         -0.01244587, -0.01182693,  0.02183693,  0.02754739,\n",
       "         -0.02321283,  0.00949694],\n",
       "        [ 0.00925181, -0.02408495, -0.04708297, -0.04156034,\n",
       "         -0.04287237, -0.02433472,  0.01309354,  0.03424022,\n",
       "          0.00653262,  0.02684298],\n",
       "        [-0.0465182 , -0.04596427,  0.02495554, -0.00350163,\n",
       "          0.01313682, -0.00038322, -0.02245554,  0.01709757,\n",
       "          0.00231581,  0.03685247],\n",
       "        [ 0.044528  ,  0.03165538,  0.04648362,  0.02596828,\n",
       "         -0.01461449,  0.02188193, -0.00256268, -0.00283493,\n",
       "          0.03548313, -0.01185352]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04967687,  0.02662567,  0.01981434, -0.01477013,\n",
       "         -0.01244587, -0.01182693,  0.02183693,  0.02754739,\n",
       "         -0.02321283,  0.00949694],\n",
       "        [ 0.00925181, -0.02408495, -0.04708297, -0.04156034,\n",
       "         -0.04287237, -0.02433472,  0.01309354,  0.03424022,\n",
       "          0.00653262,  0.02684298],\n",
       "        [-0.0465182 , -0.04596427,  0.02495554, -0.00350163,\n",
       "          0.01313682, -0.00038322, -0.02245554,  0.01709757,\n",
       "          0.00231581,  0.03685247],\n",
       "        [ 0.0286673 ,  0.03627695,  0.04871876,  0.00586675,\n",
       "          0.03517148,  0.04556647,  0.03108427, -0.02868446,\n",
       "         -0.02734913, -0.0218401 ]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04967687,  0.02662567,  0.01981434, -0.01477013,\n",
       "         -0.01244587, -0.01182693,  0.02183693,  0.02754739,\n",
       "         -0.02321283,  0.00949694],\n",
       "        [ 0.01159426,  0.00468007, -0.04547003,  0.01990345,\n",
       "          0.00531117, -0.04446422,  0.04048489, -0.00761639,\n",
       "          0.01905059, -0.0112771 ],\n",
       "        [-0.0465182 , -0.04596427,  0.02495554, -0.00350163,\n",
       "          0.01313682, -0.00038322, -0.02245554,  0.01709757,\n",
       "          0.00231581,  0.03685247],\n",
       "        [-0.0025671 , -0.03904303,  0.02450528, -0.03585631,\n",
       "          0.02535868,  0.03838929,  0.03322357, -0.0307786 ,\n",
       "          0.0111529 ,  0.02071252]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.00120788, -0.02472841, -0.009715  ,  0.01054913,\n",
       "          0.01400829, -0.02636218,  0.04179592,  0.00517061,\n",
       "          0.03965971, -0.0410838 ],\n",
       "        [-0.0172889 , -0.04453204, -0.0495036 ,  0.03950821,\n",
       "         -0.03274556,  0.0054631 , -0.04354487,  0.01883302,\n",
       "          0.02643167, -0.01834441],\n",
       "        [-0.015345  ,  0.00284297, -0.03959443,  0.0174562 ,\n",
       "          0.02331981,  0.03353259,  0.02400049,  0.02575176,\n",
       "          0.04464802, -0.00240378],\n",
       "        [-0.01027635,  0.02699417, -0.03375393,  0.04807708,\n",
       "          0.0093376 ,  0.04206643, -0.02638306,  0.0454225 ,\n",
       "          0.01667741, -0.02070252],\n",
       "        [ 0.00526055, -0.0464177 , -0.03034352, -0.01782333,\n",
       "         -0.00838138,  0.02321109,  0.01415253,  0.04921864,\n",
       "         -0.04175289, -0.01296929]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.00120788, -0.02472841, -0.009715  ,  0.01054913,\n",
       "          0.01400829, -0.02636218,  0.04179592,  0.00517061,\n",
       "          0.03965971, -0.0410838 ],\n",
       "        [-0.0172889 , -0.04453204, -0.0495036 ,  0.03950821,\n",
       "         -0.03274556,  0.0054631 , -0.04354487,  0.01883302,\n",
       "          0.02643167, -0.01834441],\n",
       "        [-0.015345  ,  0.00284297, -0.03959443,  0.0174562 ,\n",
       "          0.02331981,  0.03353259,  0.02400049,  0.02575176,\n",
       "          0.04464802, -0.00240378],\n",
       "        [-0.01027635,  0.02699417, -0.03375393,  0.04807708,\n",
       "          0.0093376 ,  0.04206643, -0.02638306,  0.0454225 ,\n",
       "          0.01667741, -0.02070252],\n",
       "        [ 0.04226274,  0.03066459, -0.04515802, -0.01638107,\n",
       "         -0.04821697,  0.02235493,  0.00639371,  0.00734418,\n",
       "          0.02625288, -0.01522859]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.03025442,  0.04734779, -0.02352071, -0.02693935,\n",
       "          0.0353307 , -0.03507185,  0.02973891, -0.04005067,\n",
       "          0.03985212, -0.00144846],\n",
       "        [-0.04967687,  0.02662567,  0.01981434, -0.01477013,\n",
       "         -0.01244587, -0.01182693,  0.02183693,  0.02754739,\n",
       "         -0.02321283,  0.00949694],\n",
       "        [ 0.02934357,  0.04053496,  0.04922752, -0.03693457,\n",
       "         -0.04750972,  0.00860741, -0.0260242 , -0.004663  ,\n",
       "         -0.00496359,  0.04159368],\n",
       "        [-0.0465182 , -0.04596427,  0.02495554, -0.00350163,\n",
       "          0.01313682, -0.00038322, -0.02245554,  0.01709757,\n",
       "          0.00231581,  0.03685247],\n",
       "        [ 0.02582086,  0.04274997, -0.01123583, -0.01874389,\n",
       "         -0.00012232,  0.01530831, -0.0458039 ,  0.04937085,\n",
       "          0.01602241,  0.01880174]],\n",
       "\n",
       "       [[-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [-0.04162744,  0.00332686,  0.04613862, -0.00371896,\n",
       "          0.0237614 , -0.00667145, -0.00117655, -0.02491373,\n",
       "          0.01515737,  0.00770762],\n",
       "        [ 0.03065861, -0.02853761, -0.01958783, -0.00680399,\n",
       "         -0.0015075 , -0.00250437, -0.00635729, -0.04435113,\n",
       "          0.04523862, -0.02705368],\n",
       "        [ 0.00116962,  0.03793532,  0.02266396,  0.01787278,\n",
       "         -0.00625795,  0.0182202 , -0.00383412, -0.00216805,\n",
       "          0.00347003, -0.01918967],\n",
       "        [-0.00902865,  0.04292259, -0.04181529,  0.01813113,\n",
       "         -0.04636857, -0.01389999, -0.01882361, -0.02284977,\n",
       "         -0.01975063, -0.02704377],\n",
       "        [-0.01027635,  0.02699417, -0.03375393,  0.04807708,\n",
       "          0.0093376 ,  0.04206643, -0.02638306,  0.0454225 ,\n",
       "          0.01667741, -0.02070252]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 3596, 5823, 1095, 5957], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_doc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ANNProject/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ANNProject/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model.predict(embedded_doc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we using One-Hot Encoding or Word2Vec to generate embeddings?\n",
    "\n",
    "We are NOT using Word2Vec.\n",
    "\n",
    "We are NOT using traditional one-hot encoding (which would generate sparse vectors).\n",
    "\n",
    "We are using integer encoding (via one_hot()) followed by an Embedding layer.\n",
    "\n",
    "The Embedding layer learns word embeddings during training similar to Word2Vec but is randomly initialized at first.\n",
    "\n",
    "### Summary\n",
    "one_hot() does NOT create one-hot vectors; it assigns a unique integer index to words.\n",
    "\n",
    "Embedding(voc_size, dim) learns dense vector representations (embeddings) for words.\n",
    "\n",
    "This is not pre-trained Word2Vec; it's a trainable embedding layer initialized randomly.\n",
    "\n",
    "If you wanted to use pre-trained Word2Vec embeddings, you would need to load a pre-trained model like GloVe or Word2Vec and set trainable=False in the Embedding layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Answer\n",
    "one_hot() gives integer encoding, which is NOT a true vector representation.\n",
    "\n",
    "Word embeddings are necessary because integer encoding lacks meaning and cannot capture relationships between words.\n",
    "\n",
    "The Embedding layer learns dense vector representations that make words with similar meanings close to each other in the embedding space.\n",
    "\n",
    "## Key Takeaway\n",
    "💡 One-hot encoding and integer encoding are different. Integer encoding is just an index, whereas word embeddings provide meaningful, dense representations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANNProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
